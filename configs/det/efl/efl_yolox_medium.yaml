num_classes: &num_classes 1204
runtime:
  aligned: true
  async_norm: true
  special_bn_init: true
  task_names: det
mosaic: &mosaic
  type: mosaic
  kwargs:
    extra_input: true
    tar_size: 640
    fill_color: 0

random_perspective: &random_perspective
  type: random_perspective_yolox
  kwargs:
    degrees: 10.0 # 0.0
    translate: 0.1
    scale: [0.1, 2.0] # 0.5
    shear: 2.0 # 0.0
    perspective: 0.0
    fill_color: 0  # 0
    border: [-320, -320]

augment_hsv: &augment_hsv
  type: augment_hsv
  kwargs:
    hgain: 0.015
    sgain: 0.7
    vgain: 0.4
    color_mode: BGR

mixup: &mixup
  type: yolox_mixup_cv2
  kwargs:
    extra_input: true
    input_size: [640, 640]
    mixup_scale: [0.8, 1.6]
    fill_color: 0

flip: &flip
  type: flip
  kwargs:
    flip_p: 0.5

to_tensor: &to_tensor
  type: custom_to_tensor

train_resize: &train_resize
  type: keep_ar_resize_max
  kwargs:
    max_size: 640
    padding_type: left_top
    padding_val: 0
    random_size: [15, 25]

test_resize: &test_resize
  type: keep_ar_resize_max
  kwargs:
    max_size: 640
    padding_type: left_top
    padding_val: 0

dataset:
  train:
    dataset:
      type: lvisv1
      kwargs:
        meta_file: lvis/annotations/lvis_v1_train.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: lvis
            color_mode: BGR
        transformer: [*mosaic, *random_perspective, *mixup, *augment_hsv, *flip, *train_resize,
          *to_tensor]
    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: repeat_factor
          kwargs:
            t: 0.001
            ri_mode: ceil
            pn: 0.5
            static_size: false
        batch_size: 8
  test:
    dataset:
      type: lvisv1
      kwargs:
        meta_file: &gt_file lvis/annotations/lvis_v1_val.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: lvis
            color_mode: BGR
        transformer: [*test_resize, *to_tensor]
        evaluator:
          type: LVIS
          kwargs:
            gt_file: *gt_file
            iou_types: [bbox]
    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: 8
  dataloader:
    type: base
    kwargs:
      num_workers: 8
      alignment: 32
      worker_init: true
      pad_type: batch_pad

trainer: # Required.
  max_epoch: &max_epoch 300             # total epochs for the training
  save_freq: 10
  test_freq: 50
  only_save_latest: true
  optimizer:                 # optimizer = SGD(params,lr=0.01,momentum=0.937,weight_decay=0.0005)
    register_type: yolov5_except
    type: SGD
    kwargs:
      lr: 0.0003125
      momentum: 0.9
      nesterov: true
      weight_decay: 0.0005      # weight_decay = 0.0005 * batch_szie / 64
      except_keys: [roi_head.cls_preds.0, roi_head.cls_preds.1, roi_head.cls_preds.2]
  lr_scheduler:
    lr_register_type: yolox_base
    warmup_epochs: 5       # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    warmup_type: yolox_cos
    type: YoloXCosineLR
    kwargs:
      T_max: *max_epoch
      min_lr_scale: 0.05
      no_aug_epoch: &no_aug_epoch 15

saver:
  save_dir: checkpoints/yolox_medium
  results_dir: results_dir/yolox_medium
  auto_resume: true

hooks:
- type: yolox_noaug
  kwargs:
    no_aug_epoch: *no_aug_epoch
    max_epoch: *max_epoch
    transformer: [*augment_hsv, *flip, *train_resize, *to_tensor]
- type: auto_save_best
- type: gradient_collector
  kwargs:
    hook_head: roi_head
    hook_cls_head: cls_preds

ema:
  enable: true
  ema_type: exp
  kwargs:
    decay: 0.9998

net:
- name: backbone
  type: yolox_m
  kwargs:
    out_layers: [2, 3, 4]
    out_strides: [8, 16, 32]
    normalize: {type: solo_bn}
    act_fn: {type: Silu}
- name: neck
  prev: backbone
  type: YoloxPAFPN
  kwargs:
    depth: &depth 0.67
    out_strides: [8, 16, 32]
    act_fn: {type: Silu}
- name: roi_head
  prev: neck
  type: YoloXHead
  kwargs:
    num_classes: *num_classes
                                 # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
    width: 0.75
    init_prior: 0.001
    num_point: &dense_points 2
    act_fn: {type: Silu}
- name: post_process
  prev: roi_head
  type: retina_post_iou
  kwargs:
    num_classes: *num_classes
                                  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
    cfg:
      cls_loss:
        type: equalized_focal_loss
        kwargs:
          num_classes: *num_classes
          focal_alpha: 0.25
          focal_gamma: 2.0
          scale_factor: 4.0
          fpn_levels: 3
      iou_branch_loss:
        type: sigmoid_cross_entropy
      loc_loss:
        type: compose_loc_loss
        kwargs:
          loss_cfg:
          - type: iou_loss
            kwargs:
              loss_type: giou
              loss_weight: 1.0
          - type: l1_loss
            kwargs:
              loss_weight: 1.0
      anchor_generator:
        type: hand_craft
        kwargs:
          anchor_ratios: [1]    # anchor strides are provided as feature strides by feature extractor
          anchor_scales: [3, 4]   # scale of anchors relative to feature map
      roi_supervisor:
        type: atss
        kwargs:
          top_n: 18
          use_iou: true
      roi_predictor:
        type: base_multicls
        kwargs:
          pre_nms_score_thresh: 0    # to reduce computation
          pre_nms_top_n: 1000
          post_nms_top_n: 1000
          roi_min_size: 0                 # minimum scale of a valid roi
          merger:
            type: retina_multicls
            kwargs:
              top_n: 300
              nms:
                type: naive
                nms_iou_thresh: 0.65
