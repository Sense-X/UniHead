num_classes: &num_classes 22
class_names: &class_names [__background__, aeroplane, bicycle, bird, boat, bottle,
  bus, car, cat, chair, cow, diningtable, dog, horse, motorbike, person, pottedplant,
  sheep, sofa, train, tvmonitor, face]
runtime:
  task_names: det

flip: &flip
  type: flip
  kwargs:
    flip_p: 0.5

resize: &resize
  type: keep_ar_resize
  kwargs:
    scales: [600]
    max_size: 1000

to_tensor: &to_tensor
  type: to_tensor

normalize: &normalize
  type: normalize
  kwargs:
    mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
    std: [0.229, 0.224, 0.225]

cross_cfg: &cross_cfg
  label_mapping: # 标签映射，第一行长度为20，代表着voc20类映射到最终输出的标签，第二行长度为1，代表人脸类别映射到最终输出的类别
  - [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
  - [21]   #
  neg_targets: [22, 23] # 这里的长度为2，代表着2个数据集的负样本标签
  gt_class_to_avoid: &gt_class_to_avoid
  - [23]   # 以下为voc的20类，需要忽略人脸的负样本23
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [23]   #
  - [22]   # face 类别需要忽略voc 的负样本 22

server_cfg: &server_cfg
  ips: [10.10.15.47] # custom-server 对应的机器Ip
  ports: [28889] # custom-server 对应的机器端口
  meta_file:
  - VOC07+12/example_list/trainval_07+12.json##1   #最后的数字表示倍数，支持浮点数
  - VOC07+12/example_list/wider_face.json##1
  cross_cfg: *cross_cfg

dataset:
  train:
    dataset:
      type: custom
      kwargs:
        # source: train  # dataset id
        num_classes: *num_classes
        class_names: *class_names
        meta_file: # 顺序必须和前面的cross_cfg 保持一致，第一个为voc，第二个数据集为face
        - VOC07+12/example_list/trainval_07+12.json
        - VOC07+12/example_list/wider_face.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: VOC07+12/JPEGImages
            color_mode: RGB
        transformer: [*flip, *resize, *to_tensor, *normalize]
        cross_cfg: *cross_cfg
                                # cross-dataset training if cfg is provided
        server_cfg: *server_cfg
                                # use server if server_cfg is provided
  test:
    dataset:
      type: custom
      kwargs:
        # source: val
        num_classes: *num_classes
        class_names: *class_names
        meta_file:
        - VOC07+12/example_list/test_07.json
        - VOC07+12/example_list/test_face.json
        image_reader:
          type: fs_opencv
          kwargs:
            image_dir: VOC07+12/JPEGImages
            color_mode: RGB
        transformer: [*resize, *to_tensor, *normalize]
        evaluator:
          type: MR               # choices = {'COCO', 'VOC', 'MR'}
          kwargs:
            gt_file:
            - VOC07+12/example_list/test_07.json
            - VOC07+12/example_list/test_face.json
            iou_thresh: 0.5
            num_classes: *num_classes
            class_names: *class_names
            cross_cfg: *cross_cfg
  batch_sampler:
    type: aspect_ratio_group
    kwargs:
      sampler:
        type: dist
        kwargs: {}
      batch_size: 2
      aspect_grouping: [1]
  dataloader:
    type: base
    kwargs:
      num_workers: 4
      alignment: 1


trainer: # Required.
  max_epoch: 14              # total epochs for the training
  test_freq: 14
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    type: SGD
    kwargs:
      lr: 0.00125
      momentum: 0.9
      weight_decay: 0.0001
  lr_scheduler:              # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 1         # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    type: MultiStepLR
    kwargs:
      milestones: [9, 12]    # epochs to decay lr
      gamma: 0.1             # decay rate

saver: # Required.
  save_dir: checkpoints     # dir to save checkpoints
  pretrain_model: resnet50-19c8e357.pth
  results_dir: results_dir  # dir to save detection results. i.e., bboxes, masks, keypoints

net:
- name: backbone                # backbone = resnet50(frozen_layers, out_layers, out_strides)
  type: resnet50
  kwargs:
    frozen_layers: [0, 1]      # layer0...1 is fixed
    out_layers: [2, 3, 4]       # layer1...4, commonly named Conv2...5
    out_strides: [8, 16, 32]    # tell the strides of output features
    normalize:
      type: freeze_bn
    initializer:
      method: msra
- name: neck
  prev: backbone
  type: FPN
  kwargs:
    outplanes: 256
    start_level: 3
    num_level: 5                  # if num_level>len(backbone.out_layers), additional conv with be stacked.
    out_strides: [8, 16, 32, 64, 128] # strides of output features. aka., anchor strides for roi_head
    downsample: conv              # method to downsample, for FPN, it's pool, for RetienaNet, it's conv
    upsample: nearest             # method to interp, nearest or bilinear
    initializer:
      method: xavier
- name: roi_head
  prev: neck
  type: RetinaSubNet
  kwargs:
    feat_planes: 256          # channels of intermediate conv
    num_classes: *num_classes
                                  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
    initializer:
      method: normal
      std: 0.01
    init_prior: 0.01
    num_anchors: 9
    class_activation: sigmoid
- name: post_process
  prev: roi_head
  type: retina_post
  kwargs:
    num_classes: *num_classes
                                  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
    cfg:
      cls_loss:
        type: cross_sigmoid_focal_loss
        kwargs:
          alpha: 0.25
          num_classes: *num_classes
          gamma: 2.0
          init_prior: 0.01
          gt_class_to_avoid: *gt_class_to_avoid
      loc_loss:
        type: smooth_l1_loss
        kwargs:
          sigma: 3.0
      anchor_generator:
        type: hand_craft
        kwargs:
          anchor_ratios: [0.5, 1, 2]  # anchor strides are provided as feature strides by feature extractor
          anchor_scales: [4, 5.0396842, 6.34960421]   # scale of anchors relative to feature map
      roi_supervisor:
        type: retina
        kwargs:
          allowed_border: -1              # >=0 for rpn, -1 for retinanet(keep all anchors)
          matcher:
            type: max_iou
            kwargs:
              positive_iou_thresh: 0.5
              negative_iou_thresh: 0.4
              ignore_iou_thresh: 0.5      # Required if provide ignore_regions        
              allow_low_quality_match: true   # an anchor is also positive if it has highest iou with any gt
          sampler:
            type: keep_all
            kwargs: {}
      roi_predictor:
        type: base
        kwargs:
          pre_nms_score_thresh: 0.05    # to reduce computation
          pre_nms_top_n: 6000
          post_nms_top_n: 1000
          roi_min_size: 0                 # minimum scale of a valid roi
          merger:
            type: retina
            kwargs:
              top_n: 100
              nms:
                type: naive
