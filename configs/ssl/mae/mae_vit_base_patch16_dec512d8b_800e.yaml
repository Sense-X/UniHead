random_resized_crop: &random_resized_crop
  type: torch_random_resized_crop
  kwargs:
    size: 224
    scale: [0.08, 1]
runtime:
  task_names: ssl
random_horizontal_flip: &random_horizontal_flip
  type: torch_random_horizontal_flip

to_tensor: &to_tensor
  type: to_tensor

normalize: &normalize
  type: normalize
  kwargs:
    mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
    std: [0.229, 0.224, 0.225]


dataset: # Required.
  train:
    dataset:
      type: cls
      kwargs:
        meta_file: images/meta/train.txt
        image_reader:
          type: fs_pillow
          kwargs:
            image_dir: images/train
            color_mode: RGB
        transformer: [*random_resized_crop, *random_horizontal_flip, *to_tensor, *normalize]
    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: 128   # Use 32 GPUs to have a total 4096 batch size
    dataloader:
      type: cls_base
      kwargs:
        num_workers: 4
        pin_memory: true

trainer: # Required.
  max_epoch: 800
  test_freq: 999999
  save_freq: 10
  only_save_latest: true
  is_eval: false
  optimizer:
    type: AdamW
    kwargs:
      lr: 0.0024
      weight_decay: 0.05
      betas: [0.9, 0.95]
    pconfig:
      ln_b:
        type: bias
        kwargs:
          weight_decay: 0.0
      ln_w:
        type: weight
        kwargs:
          weight_decay: 0.0
      linear_b:
        type: bias
        kwargs:
          weight_decay: 0.0
  lr_scheduler:
    warmup_iter: 12510
    warmup_type: linear
    warmup_register_type: no_scale_lr
    warmup_ratio: 0.05
    type: CosineLREpochScheduler
    kwargs:
      T_max: 800
      warm_epoch: 40

saver: # Required.
  save_dir: MAE_800/checkpoints/mae     # dir to save checkpoints
  results_dir: MAE_800/results_dir/mae  # dir to save detection results. i.e., bboxes, masks, keypoints
  auto_resume: true  # find last checkpoint from save_dir and resume from it automatically
                     # this option has the highest priority (auto_resume > opts > resume_model > pretrain_model)

hooks:
- type: auto_save_best

net:
- name: backbone
  type: ssl
  multi_model:
  - name: model
    type: mae_vit_base_patch16_dec512d8b
    kwargs:
      mask_ratio: 0.75
  wrappers:
  - type: MAE

- name: post_process
  type: base_ssl_postprocess
  kwargs:
    ssl_loss:
      type: mae_loss
      norm_pix_loss: false     # Baseline --> False, Set to True will improve downstream performance
