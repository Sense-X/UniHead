cls_classes: &cls_classes 1000
det_classes: &det_classes 81

runtime:
  fp16:
    keep_batchnorm_fp32: true
    scale_factor: dynamic
  runner:
    type: multitask
  task_names: &task_names [det]

augs:
  det:
    flip: &flip
      type: flip
      kwargs:
        flip_p: 0.5


    resize: &resize
      type: keep_ar_resize
      kwargs:
        scales: [800]
        max_size: 1333

    mosaicv2:
      type: mosaic
      kwargs:
        extra_input: true
        tar_size: 1024
        fill_color: 0

    random_perspective:
      type: random_perspective
      kwargs:
        degrees: 0.0
        translate: 0.1
        scale: 0.5
        shear: 0.0
        perspective: 0.0
        border: [-512, -512]
        fill_color: 0

    augment_hsv:
      type: augment_hsv
      kwargs:
        hgain: 0.015
        sgain: 0.7
        vgain: 0.4

  cls:
    random_resized_crop: &random_resized_crop
      type: torch_random_resized_crop
      kwargs:
        size: 224
        scale: [0.08, 1]
    random_horizontal_flip: &random_horizontal_flip
      type: torch_random_horizontal_flip

    pil_color_jitter: &pil_color_jitter
      type: torch_color_jitter
      kwargs:
        brightness: 0.2
        contrast: 0.2
        saturation: 0.2
        hue: 0.1

    center_crop: &center_crop
      type: torch_center_crop
      kwargs:
        size: 224

    torch_size: &torch_resize
      type: torch_resize
      kwargs:
        size: 256

  common:
    to_tensor: &to_tensor
      type: to_tensor

    normalize: &normalize
      type: normalize
      kwargs:
        mean: [0.485, 0.456, 0.406] # ImageNet pretrained statics
        std: [0.229, 0.224, 0.225]


settings:
  memcached: &memcached true
  det_batch: &det_batch 8
  det_workers: &det_workers 8
  cls_batch: &cls_batch 128
  cls_workers: &cls_workers 8

dataset: # Required.
  train:
    dataset:
      type: coco
      kwargs:
        has_semantic_seg: false
        has_mask: false
        source: train  # dataset id
        meta_file: coco/annotations/instances_train2017.json
        image_reader:
          type: fs_pillow
          kwargs:
            image_dir: coco/train2017
            color_mode: RGB
            memcached: *memcached
        transformer: [*flip, *resize, *to_tensor, *normalize]
        # transformer: [*mosaic, *random_perspective, *augment_hsv, *flip, *to_tensor, *normalize]
    batch_sampler:
      type: aspect_ratio_group
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: *det_batch
        aspect_grouping: [1]
    dataloader:
      type: base
      kwargs:
        num_workers: *det_workers
        alignment: 32

  test:
    dataset:
      type: coco
      kwargs:
        source: val
        meta_file: coco/annotations/instances_val2017.json

        image_reader:
          type: fs_pillow
          kwargs:
            image_dir: coco/val2017
            color_mode: RGB
            memcached: *memcached
        transformer: [*resize, *to_tensor, *normalize]

        evaluator:
          type: COCO
          kwargs:
            gt_file: coco/annotations/instances_val2017.json
            iou_types: [bbox]

    batch_sampler:
      type: aspect_ratio_group
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: *det_batch
        aspect_grouping: [1]
    dataloader:
      type: base
      kwargs:
        num_workers: *det_workers
        alignment: 32


  train_cls:
    dataset:
      type: cls
      kwargs:
        meta_file: images_1k/meta/train.txt
        image_reader:
          type: fs_pillow
          kwargs:
            image_dir: images_1k/train
            color_mode: RGB
            memcached: *memcached
        transformer: [*random_resized_crop, *random_horizontal_flip, *pil_color_jitter,
          *to_tensor, *normalize]
    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: *cls_batch
    dataloader:
      type: cls_base
      kwargs:
        num_workers: *cls_workers
        pin_memory: true

  test_cls:
    dataset:
      type: cls
      kwargs:
        meta_file: images_1k/meta/val.txt
        image_reader:
          type: fs_pillow
          kwargs:
            image_dir: images_1k/val
            color_mode: RGB
            memcached: *memcached
        transformer: [*torch_resize, *center_crop, *to_tensor, *normalize]
        evaluator:
          type: imagenet               # choices = {'COCO', 'VOC', 'MR'}
          kwargs:
            topk: [1, 5]
    batch_sampler:
      type: base
      kwargs:
        sampler:
          type: dist
          kwargs: {}
        batch_size: *cls_batch
    dataloader:
      type: cls_base
      kwargs:
        num_workers: *cls_workers
        pin_memory: false

multitask_cfg:
  notions:
    det: 0
    cls: &cls 1
  datasets:
    train: [train]
    test: [test]
  task_names: *task_names
                          # [det]
  debug: &multitask_debug false

trainer: # Required.
  max_epoch: 14              # total epochs for the training
  test_freq: 1
  save_freq: 1
  only_save_latest: true
  optimizer:                 # optimizer = SGD(params,lr=0.001,momentum=0.9,weight_decay=0.0001)
    # register_type: swin
    type: FusedFP16AdamW
    kwargs:
      lr: 6.25e-06
      betas: [0.9, 0.999]
      weight_decay: 0.05
  lr_scheduler: # lr_scheduler = MultStepLR(optimizer, milestones=[9,14],gamma=0.1)
    warmup_epochs: 1         # set to be 0 to disable warmup. When warmup,  target_lr = init_lr * total_batch_size
    type: MultiStepLR
    kwargs:
      milestones: [9, 12]      # epochs to decay lr
      gamma: 0.1             # decay rate



saver: # Required.
  save_dir: checkpoints     # dir to save checkpoints
  results_dir: results_dir/  # dir to save detection results. i.e., bboxes, masks, keypoints
  auto_resume: true  # find last checkpoint from save_dir and resume from it automatically
                     # this option has the highest priority (auto_resume > opts > resume_model > pretrain_model)
  pretrain_model: resnet50-19c8e357.pth

hooks:
- type: auto_save_best_multitask
- type: auto_save_metric

norms:
  sync_bn: # &norm
    type: sync_bn
    kwargs:
      group_size: 8
  task_sync_bn: &norm
    type: task_sync_bn
    kwargs:
      group_size: 8
      task_num: 2


net:
- name: backbone                # backbone = resnet50(frozen_layers, out_layers, out_strides)
  type: resnet50
  kwargs:
      #      frozen_layers: [ 1,2,3,4 ]     # layer0...1 is fixed
    out_layers: [2, 3, 4]         # layer1...4, commonly named Conv2...5
    out_strides: [8, 16, 32]      # tell the strides of output features
    normalize: *norm
    initializer:
      method: xavier

- name: neck
  prev: backbone
  type: FPN
  kwargs:
    outplanes: 256
    start_level: 3
    num_level: 5                  # if num_level>len(backbone.out_layers), additional conv with be stacked.
    out_strides: [8, 16, 32, 64, 128] # strides of output features. aka., anchor strides for roi_head
    downsample: conv              # method to downsample, for FPN, it's pool, for RetienaNet, it's conv
    upsample: deconv              # method to interp, nearest or bilinear
    initializer:
      method: xavier
    normalize: *norm

- name: roi_head
  prev: neck
  type: RetinaHeadWithBN
  kwargs:
    feat_planes: 256          # channels of intermediate conv
    num_classes: *det_classes
                                  # number of classes including backgroudn. for rpn, it's 2; for RetinaNet, it's 81
    initializer:
      method: normal
      std: 0.01
    num_level: 5
    num_conv: 4
    normalize: *norm
    init_prior: 0.01
    num_anchors: 2
    class_activation: sigmoid
  wrappers:
  - &det_wrapper
    type: multitask_wrapper
    kwargs:
      cfg:
        idxs: [0]
        debug: *multitask_debug

- name: retina_process
  prev: roi_head
  type: retina_post
  kwargs:
    num_classes: *det_classes
    cfg:
      cls_loss:
        type: quality_focal_loss
        kwargs:
          gamma: 2.0
          init_prior: 0.01
          dynamic_normalizer: true
      loc_loss:
        type: iou_loss
        kwargs:
          loss_type: giou
          loss_weight: 1.0
      anchor_generator:
        type: hand_craft
        kwargs:
          anchor_ratios: [1]      # anchor strides are provided as feature strides by feature extractor
          anchor_scales: [6, 8]     # scale of anchors relative to feature map
      roi_supervisor:
        type: atss
        kwargs:
          top_n: 18
      roi_predictor:
        type: base
        kwargs:
          pre_nms_score_thresh: 0.05    # to reduce computation
          pre_nms_top_n: 1000
          post_nms_top_n: 1000
          roi_min_size: 0                 # minimum scale of a valid roi
          merger:
            type: retina
            kwargs:
              top_n: 100
              nms:
                type: naive
                nms_iou_thresh: 0.5       # Required in RetinaNet. DO not nms in FPN across levels
  wrappers:
  - *det_wrapper

- name: cls_head
  type: fpn_cls_head
  prev: neck
  kwargs:
    num_classes: *cls_classes
    feat_planes: &head_out_channel 512
    sum_feature: true
  wrappers:
  - &cls_wrapper
    type: multitask_wrapper
    kwargs:
      cfg:
        idxs: [*cls]
        debug: *multitask_debug

- name: post_process
  type: base_cls_postprocess
  kwargs:
    cls_loss:
      type: label_smooth_ce
      kwargs:
        smooth_ratio: 0.1
        num_classes: *cls_classes
        loss_weight: 0.1
  wrappers:
  - *cls_wrapper
